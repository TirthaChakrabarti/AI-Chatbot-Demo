{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db16bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# import openai\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04df9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client, model_name, messages, temperature=0.0):\n",
    "    input_messages = []\n",
    "    for message in messages: \n",
    "        input_messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=input_messages,\n",
    "        temperature=temperature,  # no randomness desired as agent-based system will depend on each other\n",
    "        top_p=0.8,\n",
    "        max_tokens=2000  # word or sub-word\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf68d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Llama endpoint\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv('RUNPOD_TOKEN'),\n",
    "    base_url = os.getenv('RUNPOD_CHATBOT_URL')\n",
    ")\n",
    "\n",
    "# openai.api_key = os.getenv('RUNPOD_TOKEN')\n",
    "# openai.api_base_url = os.getenv('RUNPOD_CHATBOT_URL')\n",
    "\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "print(model_name)\n",
    "# print(client.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"What is the capital of India?\"}\n",
    "]\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cddefa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "{'error': 'You do not have permission to perform this action.'}\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "RUNPOD_TOKEN = os.getenv(\"RUNPOD_TOKEN\")\n",
    "RUNPOD_CHATBOT_URL = os.getenv(\"RUNPOD_CHATBOT_URL\")  # e.g., https://<your-id>.proxy.runpod.net/v1\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {RUNPOD_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"meta-llama/Llama-3.1-8B-Instruct\",  \n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of India?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 200\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{RUNPOD_CHATBOT_URL}/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853280a",
   "metadata": {},
   "source": [
    "# Promt Engineering\n",
    "\n",
    "## Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions about the capitals of countries.\n",
    "\n",
    "Your output should be a structured JSON format exactly like the one below. You are not allowed to write anything other than JSON object:\n",
    "\n",
    "{\n",
    "    \"country\": the country that you will get the capital of,\n",
    "    \"capital\": the capital of the country stated\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "]\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"What is the capital of India?\"})\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)  # string\n",
    "\n",
    "json_response = json.loads(response)\n",
    "\n",
    "print(json_response)\n",
    "\n",
    "type(json_response)  # list\n",
    "type(json_response[0])  # dict\n",
    "\n",
    "json_response[0][\"country\"]  # \"India\"\n",
    "json_response[0][\"capital\"]  # \"New Delhi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf381b4",
   "metadata": {},
   "source": [
    "## Input Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2fd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\" \n",
    "    Get me the capital of the following countries:\n",
    "    ```\n",
    "        1. Italy\n",
    "        2. France\n",
    "        3. Germany\n",
    "\n",
    "    ```\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "]\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)  # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10514a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = json.loads(response)\n",
    "\n",
    "print(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c42bfc",
   "metadata": {},
   "source": [
    "## Give the model time to think (Chain of Thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Calculate the result of this equation: 1+3\n",
    "    \n",
    "    Your output should be a structured JSON format exactly like the one below. You are not allowed to write anything other than JSON object:\n",
    "    \n",
    "    {\n",
    "        \"result\": the final number resulted from calculating the equation above\n",
    "    }\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)\n",
    "\n",
    "# But making the equation complex will cause the model to fail and give incorrect result\n",
    "# We can make the accuracy better by telling it to do the calculation step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8949c0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94537.58377425044"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1234*43/567-123+94567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b23d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "    Calculate the result of this equation: 1234*43/567-123+94567\n",
    "    \n",
    "    Your output should be a structured JSON format exactly like the one below. You are not allowed to write anything other than JSON object:\n",
    "    \n",
    "    {\n",
    "        \"result\": the final number resulted from calculating the equation above\n",
    "    }\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the code again\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Calculate the result of this equation: 1234*43/567-123+94567\n",
    "    \n",
    "    Your output should be a structured JSON format exactly like the one below. You are not allowed to write anything other than JSON object:\n",
    "    \n",
    "    {\n",
    "        \"steps: This is where you solve the equation bit by bit following  the BEDMAS rule. You need to show your work and calculate each step leading to the final result. Feel free to write in free text\",\n",
    "        \"result\": the final number resulted from calculating the equation above\n",
    "    }\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63a6cb",
   "metadata": {},
   "source": [
    "# RAG - Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32650e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "    What's new in iPhone 16?\n",
    "\"\"\"\n",
    "\n",
    "# Our LLM (Llama-3.1-8B-Instruct) does not know the existance of iPhone 16\n",
    "# It was released after the model was trained\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "iPhone_16 = \"\"\"\n",
    "The iPhone 16 lineup brings notable upgrades: faster and smarter processing (A18 chip), expanded AI readiness, advanced camera features including a dedicated camera control button, improved battery and safety tools, and better customization with Photographic Styles. Whether you go for the standard or Pro version, Apple’s renewed focus on on-device intelligence and user control is its biggest leap since the iPhone X era.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"\n",
    "    {iPhone_16}\n",
    "\n",
    "    What's new in iPhone 16?\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "response = get_chatbot_response(client, model_name, messages)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

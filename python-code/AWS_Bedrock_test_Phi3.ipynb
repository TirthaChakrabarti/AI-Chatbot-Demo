{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30d209ed",
   "metadata": {},
   "source": [
    "# AWS Bedrock Phi3 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "085546ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create Bedrock runtime client\n",
    "client = boto3.client(\"sagemaker-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Model ID for Phi-3 on Bedrock\n",
    "MODEL_ID = \"huggingface-llm-phi-3-mini-4k-instruct\"\n",
    "\n",
    "def build_chat_prompt(messages):\n",
    "    \"\"\"\n",
    "    Convert OpenAI-style messages into a single prompt string.\n",
    "    Example:\n",
    "    [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    "    -->\n",
    "    \"System: You are a helpful assistant.\\nUser: Hello!\\nAssistant:\"\n",
    "    \"\"\"\n",
    "    prompt = \"\"\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"].capitalize()\n",
    "        content = msg[\"content\"]\n",
    "        prompt += f\"{role}: {content}\\n\"\n",
    "    prompt += \"Assistant:\"  # signal Phi-3 to continue\n",
    "    return prompt\n",
    "\n",
    "def get_chatbot_response(client, model_id, messages, temperature=0.7, top_p=0.9, max_tokens=512):\n",
    "    # Build prompt from role+content messages\n",
    "    prompt = build_chat_prompt(messages)\n",
    "\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"max_new_tokens\": max_tokens\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Call Bedrock model\n",
    "    response = client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(payload),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "\n",
    "    # Parse the response body\n",
    "    result = json.loads(response[\"body\"].read())\n",
    "\n",
    "    # Hugging Face models return a list with generated text\n",
    "    if isinstance(result, list):\n",
    "        return result[0].get(\"generated_text\", \"\").strip()\n",
    "    return result.get(\"generated_text\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9692f756",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SageMakerRuntime' object has no attribute 'invoke_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert IT consultant.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the most important domains in IT currently?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get response\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_chatbot_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n",
      "Cell \u001b[1;32mIn[17], line 41\u001b[0m, in \u001b[0;36mget_chatbot_response\u001b[1;34m(client, model_id, messages, temperature, top_p, max_tokens)\u001b[0m\n\u001b[0;32m     31\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     }\n\u001b[0;32m     38\u001b[0m }\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Call Bedrock model\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m(\n\u001b[0;32m     42\u001b[0m     modelId\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[0;32m     43\u001b[0m     body\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(payload),\n\u001b[0;32m     44\u001b[0m     contentType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     accept\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Parse the response body\u001b[39;00m\n\u001b[0;32m     49\u001b[0m result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32mc:\\Users\\chakr\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\botocore\\client.py:969\u001b[0m, in \u001b[0;36mBaseClient.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m event_response\n\u001b[1;32m--> 969\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SageMakerRuntime' object has no attribute 'invoke_model'"
     ]
    }
   ],
   "source": [
    "# Example messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert IT consultant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are the most important domains in IT currently?\"}\n",
    "]\n",
    "\n",
    "# Get response\n",
    "response = get_chatbot_response(client, MODEL_ID, messages)\n",
    "print(\"Assistant:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
